{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6426dd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa2feca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ssp1_\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Data:\n",
      "    pagePath previousPagePath  pageviews  sessions  users\n",
      "0      /home        /products        120        90     85\n",
      "1      /home                /        100        80     70\n",
      "2  /products           /about         80        70     65\n",
      "3     /about                /         60        50     45\n",
      "4     /about            /home         50        40     35\n",
      "5  /products            /home         40        35     30\n",
      "6   /contact            /home         30        25     20\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = r'C:\\Users\\AKHILA\\OneDrive\\Desktop\\mini_projsample_google_analytics_data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Function for noise reduction\n",
    "def reduce_noise(data, pageviews_threshold=20, sessions_threshold=15, users_threshold=10):\n",
    "    \"\"\"\n",
    "    Reduces noise in web analytics data by filtering rows with metrics below thresholds.\n",
    "    \n",
    "    Parameters:\n",
    "        data (pd.DataFrame): The input dataset.\n",
    "        pageviews_threshold (int): Minimum pageviews to retain a row.\n",
    "        sessions_threshold (int): Minimum sessions to retain a row.\n",
    "        users_threshold (int): Minimum users to retain a row.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Cleaned dataset.\n",
    "    \"\"\"\n",
    "    # Filter rows based on thresholds\n",
    "    filtered_data = data[\n",
    "        (data['pageviews'] >= pageviews_threshold) &\n",
    "        (data['sessions'] >= sessions_threshold) &\n",
    "        (data['users'] >= users_threshold)\n",
    "    ]\n",
    "    \n",
    "    # Sort the filtered data for easier analysis\n",
    "    filtered_data = filtered_data.sort_values(by='pageviews', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    return filtered_data\n",
    "\n",
    "# Apply the noise-reduction function to the dataset\n",
    "cleaned_data = reduce_noise(data)\n",
    "\n",
    "# Display the cleaned data\n",
    "print(\"Cleaned Data:\")\n",
    "print(cleaned_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08cea5cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Processed Data:\n",
      "    pagePath previousPagePath  pageviews  sessions  users  cluster\n",
      "0      /home                /        100        80     70        1\n",
      "1     /about            /home         50        40     35        0\n",
      "2   /contact            /home         30        25     20        0\n",
      "3  /products            /home         40        35     30        0\n",
      "4  /products           /about         80        70     65        1\n",
      "5     /about                /         60        50     45        1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ssp1_\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1411: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Load the dataset\n",
    "file_path = r'C:\\Users\\ssp1_\\Downloads\\sample_google_analytics_data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Function for outlier detection using Isolation Forest\n",
    "def detect_outliers(data, contamination=0.1):\n",
    "    \"\"\"\n",
    "    Detects outliers in numerical data using Isolation Forest.\n",
    "    \n",
    "    Parameters:\n",
    "        data (pd.DataFrame): The input dataset.\n",
    "        contamination (float): Proportion of outliers in the data.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Dataset with an added 'outlier' column.\n",
    "    \"\"\"\n",
    "    # Selecting numerical columns\n",
    "    numerical_data = data[['pageviews', 'sessions', 'users']]\n",
    "    \n",
    "    # Apply Isolation Forest\n",
    "    model = IsolationForest(contamination=contamination, random_state=42)\n",
    "    data['outlier'] = model.fit_predict(numerical_data)\n",
    "    \n",
    "    # Retain non-outliers (outlier = 1)\n",
    "    filtered_data = data[data['outlier'] == 1].drop(columns=['outlier']).reset_index(drop=True)\n",
    "    return filtered_data\n",
    "\n",
    "# Function for clustering using KMeans\n",
    "def cluster_data(data, n_clusters=2):\n",
    "    \"\"\"\n",
    "    Groups similar patterns in the data using KMeans clustering.\n",
    "    \n",
    "    Parameters:\n",
    "        data (pd.DataFrame): The input dataset.\n",
    "        n_clusters (int): Number of clusters.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Dataset with an added 'cluster' column.\n",
    "    \"\"\"\n",
    "    # Selecting numerical columns\n",
    "    numerical_data = data[['pageviews', 'sessions', 'users']]\n",
    "    \n",
    "    # Apply KMeans\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    data['cluster'] = kmeans.fit_predict(numerical_data)\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Step 1: Detect and remove outliers\n",
    "data_no_outliers = detect_outliers(data)\n",
    "\n",
    "# Step 2: Cluster the cleaned data\n",
    "clustered_data = cluster_data(data_no_outliers)\n",
    "\n",
    "# Display the final processed data\n",
    "print(\"Final Processed Data:\")\n",
    "print(clustered_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9792ae42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
